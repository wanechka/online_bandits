# online_bandits
Different online multiarmed bandits algorithm comparison (RL-project within the Summer School on AI by RAAI)
